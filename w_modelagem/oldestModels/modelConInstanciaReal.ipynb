{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type:ignore\n",
    "import time\n",
    "import sys\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from gurobipy import *\n",
    "from functions3 import *\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parâmetros\n",
    "instances = [\n",
    "            #  'instancia1'\n",
    "            #  'instancia2',\n",
    "            #  'instancia3',\n",
    "            #  'instancia4',\n",
    "            #  'instancia5',\n",
    "            #  'instancia6',\n",
    "            #  'instancia7',\n",
    "            #  'instancia8',\n",
    "            #  'instancia9',\n",
    "            #  'instancia10'\n",
    "            #  'test4',\n",
    "            #  'test5',\n",
    "             'test1'\n",
    "            ]\n",
    "\n",
    "# Qs = [561]#,637,563,561,561,565,491,493,563,493] estos eram los máximos\n",
    "Qs = {\n",
    "      # 'instancia1':{'P':561, 'Z':561}#,\n",
    "    #   'instancia2':{'P':633, 'Z':633},\n",
    "      # 'instancia3':{'P':419, 'Z':419},\n",
    "      # 'instancia4':{'P':561, 'Z':561},\n",
    "      # 'instancia5':{'P':417, 'Z':417}#,\n",
    "      # 'instancia6':{'P':493, 'Z':493},\n",
    "      # 'instancia7':{'P':491, 'Z':491},\n",
    "      # 'instancia8':{'P':493, 'Z':493},\n",
    "      # 'instancia9':{'P':419, 'Z':419},\n",
    "      # 'instancia10':{'P':493, 'Z':493}\n",
    "      # 'test4':{'P':559, 'Z':559},\n",
    "      # 'test5':{'P':493, 'Z':493},\n",
    "      'test1':{'P':559, 'Z':559}\n",
    "      } # estas son las minímas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_excel = '/home/wilmer/Documentos/Codes/tesis/Instancias/test/resumo.xlsx'\n",
    "wb = load_workbook(path_excel)\n",
    "hoja = wb.active\n",
    "\n",
    "for instance in instances:\n",
    "    \n",
    "    path = '/home/wilmer/Documentos/Codes/tesis/Instancias/test/'+instance\n",
    "    Q = Qs[instance]\n",
    "\n",
    "    modelos = [\n",
    "            #    BaseModel#,\n",
    "            #    BaseModel_Fulfillments,\n",
    "            #    BaseModel_Skiplagging,\n",
    "            #    BaseModel_Fulfillments_Skiplagging\n",
    "\n",
    "            #    HierarBehavioralModel,\n",
    "            #    HierarBehavioralModel_Fulfillments,\n",
    "            #    HierarBehavioralModel_Skiplagging,\n",
    "            #    HierarBehavioralModel_Fulfillments_Skiplagging\n",
    "\n",
    "            #    PercentBehavioralModel,\n",
    "            #    PercentBehavioralModel_Fulfillments,\n",
    "            #    PercentBehavioralModel_Skiplagging,\n",
    "               PercentBehavioralModel_Fulfillments_Skiplagging\n",
    "            ]\n",
    "\n",
    "    for classeModelo in modelos:\n",
    "\n",
    "        # criar modelo\n",
    "        start_time_cria_model = time.time()\n",
    "\n",
    "        modelo = classeModelo(\n",
    "            path_dem = path + '/demanda.csv',\n",
    "            path_preco = path + '/preco.csv',\n",
    "            path_rota1 = path + '/rota.csv',\n",
    "            Q = Q,\n",
    "            perio = 0\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            model, A, X, Y, BY, BX, BL, BD, P, d, perio, indexCombiDem, mtr = modelo.create_model()\n",
    "        except:  \n",
    "            # model, A, X, Y, BY, BX, BL, BD, P, d, perio, indexCombiDem = modelo.create_model()\n",
    "            model, A, X, Y, BY, BX, BL, BD, P, d, perio, indexCombiDem = modelo.create_model()\n",
    "\n",
    "\n",
    "        end_time_cria_model = time.time()\n",
    "\n",
    "        # Redigir a saída padrão para um arquivo\n",
    "        old_stdout = sys.stdout\n",
    "        new_stdout = io.StringIO()\n",
    "        sys.stdout = new_stdout\n",
    "\n",
    "        # Optimizar o modelo\n",
    "        start_time_opt = time.time()\n",
    "\n",
    "        model.optimize()\n",
    "        model.write(path+'/modelo.lp')\n",
    "        end_time_opt = time.time()\n",
    "\n",
    "        # Calcular tempos\n",
    "        tempoCriacao = end_time_cria_model - start_time_cria_model\n",
    "        tempoOpt = end_time_opt - start_time_opt\n",
    "\n",
    "        if model.status == GRB.OPTIMAL:\n",
    "            # Salvar solução\n",
    "            if classeModelo.__name__ == 'BaseModel_Fulfillments_Skiplagging':\n",
    "                a = save_solution(model, BX, BL, BD, P, d, X, Y, A, BY, perio, classeModelo.__name__, indexCombiDem, {} , path)\n",
    "            else:\n",
    "                a = save_solution(model, BX, BL, BD, P, d, X, Y, A, BY, perio, classeModelo.__name__, indexCombiDem, mtr, path)\n",
    "\n",
    "            print(\"Modelo: \", classeModelo.__name__)\n",
    "            print(\"Instancia: \", instance)\n",
    "            print(\"FO: \", model.ObjVal)\n",
    "            print(\"FO Relaxada: \", model.ObjBound)\n",
    "            print(\"Tempo Criação: \", tempoCriacao)\n",
    "            print(\"Tempo da optimização: \", tempoOpt)\n",
    "        else:\n",
    "            print(\"Modelo: \", classeModelo.__name__)\n",
    "            print(\"Instancia: \", instance)\n",
    "            print(\"FO: \", \"Infac\")\n",
    "            print(\"FO Relaxada: \", model.ObjBound)\n",
    "            print(\"Tempo Criação: \", tempoCriacao)\n",
    "            print(\"Tempo da optimização: \", tempoOpt)\n",
    "\n",
    "        # Voltar a saída padrão\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "        # Obter a saída da otimização\n",
    "        output = new_stdout.getvalue()\n",
    "\n",
    "        # Salvar a saída num arquivo de texto\n",
    "        with open( path + '/'+ classeModelo.__name__ +'.txt', 'w') as f:\n",
    "            f.write(output)\n",
    "\n",
    "        # Salvar em excel um resumo dos resultados\n",
    "        if model.status == GRB.OPTIMAL:\n",
    "            hoja.append([instance, classeModelo.__name__, model.NumVars, tempoCriacao, tempoOpt, model.NodeCount, model.IterCount, model.SolCount, model.MIPGap, model.ObjBound, model.ObjVal])\n",
    "        else:\n",
    "            hoja.append([instance, classeModelo.__name__, model.NumVars, tempoCriacao, tempoOpt, \"-\", \"-\", \"-\", \"-\", \"-\",'Infactível'])\n",
    "        wb.save(path_excel)\n",
    "\n",
    "\n",
    "        # # Obtener restricciones y variables\n",
    "        # variables = model.getVars()\n",
    "        # restricciones = model.getConstrs()\n",
    "\n",
    "        # # Crear matriz MA\n",
    "        # MA = []\n",
    "        # for constr in restricciones:\n",
    "        #     fila = [model.getCoeff(constr, var) for var in variables]  # Obtener coeficiente de cada variable en la restricción\n",
    "        #     MA.append(fila)\n",
    "\n",
    "        # # Convertir la matriz A en un DataFrame\n",
    "        # import pandas as pd\n",
    "        # A_df = pd.DataFrame(MA, columns=[var.VarName for var in variables], index=[constr.ConstrName for constr in restricciones])\n",
    "\n",
    "        # # Exportar la matriz A a CSV\n",
    "        # A_df.to_csv(path+\"matriz_A.csv\", index=True)\n",
    "\n",
    "\n",
    "        print(\"Termino a Instancia: \" + instance + \", usando o modelo: \" + classeModelo.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelo.lp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.write(\"modelo.lp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el modelo LP\n",
    "modelop = read(\"modelo.lp\")  # Asegúrate de que esté en el mismo directorio\n",
    "\n",
    "# Asegurar que el modelop está actualizado\n",
    "modelop.update()\n",
    "\n",
    "# Extraer matriz de restricciones\n",
    "A = modelop.getA()\n",
    "\n",
    "# Extraer nombres de variables (columnas de A)\n",
    "variables = [v.VarName for v in modelop.getVars()]\n",
    "\n",
    "# Extraer nombres de restricciones (filas de A)\n",
    "restricciones = [c.ConstrName for c in modelop.getConstrs()]\n",
    "\n",
    "# Extraer lado derecho (b)\n",
    "b = [c.RHS for c in modelop.getConstrs()]\n",
    "\n",
    "# Convertir la matriz dispersa a DataFrame\n",
    "A_df = pd.DataFrame.sparse.from_spmatrix(A, index=restricciones, columns=variables)\n",
    "\n",
    "# Convertir b a Series\n",
    "b_series = pd.Series(b, index=restricciones, name='b')\n",
    "\n",
    "# Mostrar resultado\n",
    "# print(\"Matriz A (coeficientes de las restricciones):\")\n",
    "# print(A_df)\n",
    "\n",
    "# print(\"\\nVector b (lado derecho):\")\n",
    "# print(b_series)\n",
    "\n",
    "# print(\"\\nVector x (variables):\")\n",
    "# print(pd.Series(variables, name='x'))\n",
    "\n",
    "A_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_df.max(axis=1).max()\n",
    "A_df.min(axis=1).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_df.columns.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.getA()\n",
    "A_dense = A.toarray()\n",
    "A_dense = pd.DataFrame(A_dense)\n",
    "A_dense.to_csv(path+\"matriz_A.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Agrupar por las columnas especificadas y calcular la suma de 'x' y 'y'\n",
    "# pd.pivot_table(a, index=[\"Origen\",\"Destino\",'Vagon','Periodo','Classe'], values=['Assignments[X]','Authorizations[Y]'], aggfunc='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPLEMENTOS [MATRIZ UNIMODULAR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from itertools import combinations\n",
    "\n",
    "# def is_unimodular(matrix):\n",
    "#     \"\"\"\n",
    "#     Comprueba si una matriz es unimodular.\n",
    "#     Una matriz es unimodular si todos sus subdeterminantes son 0, 1 o -1.\n",
    "\n",
    "#     Parámetros:\n",
    "#     matrix (np.array): Matriz cuadrada o rectangular a analizar.\n",
    "\n",
    "#     Retorna:\n",
    "#     True si la matriz es unimodular, False en caso contrario.\n",
    "#     \"\"\"\n",
    "#     rows, cols = matrix.shape\n",
    "#     min_dim = min(rows, cols)  # Tamaño máximo de las submatrices cuadradas\n",
    "\n",
    "#     for k in range(1, min_dim + 1):  # Orden de submatrices cuadradas\n",
    "#         row_indices = list(combinations(range(rows), k))\n",
    "#         col_indices = list(combinations(range(cols), k))\n",
    "\n",
    "#         for r in row_indices:\n",
    "#             for c in col_indices:\n",
    "#                 submatrix = matrix[np.ix_(r, c)]  # Extraer submatriz cuadrada\n",
    "#                 det = round(np.linalg.det(submatrix))  # Determinante redondeado\n",
    "#                 if det not in [0, 1, -1]:  # Verificar condición de unimodularidad\n",
    "#                     print(f\"Submatriz no unimodular encontrada:\\n{submatrix}\")\n",
    "#                     print(f\"Determinante: {det}\")\n",
    "#                     return False\n",
    "#     return True\n",
    "\n",
    "# # Cargar la matriz A desde un archivo CSV\n",
    "# file_path = \"/home/wilmer/Documentos/Codes/tesis/Instancias/testmatriz_A.csv\"  # Asegúrate de reemplazarlo por la ruta correcta\n",
    "# A_df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# # Convertir el DataFrame a un array NumPy\n",
    "# A = A_df.to_numpy()\n",
    "\n",
    "# # Verificar la unimodularidad\n",
    "# if is_unimodular(A):\n",
    "#     print(\"La matriz A es unimodular.\")\n",
    "# else:\n",
    "#     print(\"La matriz A no es unimodular.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dem = pd.read_csv(path + '/demanda.csv')\n",
    "# periodos = sorted(dem['DBD'].unique())\n",
    "# periodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrs = ['Authorizations[Y]','Assignments[X]','Demanda','Preco']\n",
    "\n",
    "# for i in periodos:\n",
    "#     graf2 = grafica(a,attrs, 2, 11, 4, i)\n",
    "#     # graf1 = grafica(a,attrs, 2, 15, 4, 1)\n",
    "#     # graf0 = grafica(a,attrs, 2, 15, 4, 0)\n",
    "\n",
    "# graf2.savefig(path+'/img2.png', dpi=300, transparent=True)\n",
    "# graf1.savefig(path+'/img1.png', dpi=300, transparent=True)\n",
    "# graf0.savefig(path+'/img0.png', dpi=300, transparent=True)\n",
    "\n",
    "# for instance in instances:\n",
    "\n",
    "#     path = '/home/wilmer/Documentos/Codes/tesis/Instancias/'+instance\n",
    "#     data = pd.read_csv(path + '/demanda.csv')\n",
    "#     data['new'] = data['Vagon'] + data['Class'].astype(str) \n",
    "#     # print(instance + \" = \"+ str(data.DBD.nunique()))\n",
    "#     print(instance + \" = \"+ str(data.new.nunique()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
